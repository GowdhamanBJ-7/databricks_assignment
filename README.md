Databricks Assignment ğŸš€

This project demonstrates an end-to-end ETL pipeline in Databricks with multi-layer architecture (Source â†’ Bronze â†’ Silver â†’ Gold) and an API ingestion pipeline using PySpark & Delta Lake.

ğŸ“‚ Project Structure
databricks_assignment/
â”‚
â”œâ”€â”€ source_to_bronze/
â”‚   â”œâ”€â”€ utils.py / utils notebook   # Reusable helper functions
â”‚   â””â”€â”€ employee_source_to_bronze   # Driver notebook: reads raw CSVs â†’ Bronze
â”‚
â”œâ”€â”€ bronze_to_silver/
â”‚   â””â”€â”€ employee_bronze_to_silver   # Cleansing & schema enforcement â†’ Silver
â”‚
â”œâ”€â”€ silver_to_gold/
â”‚   â””â”€â”€ employee_silver_to_gold     # Transformations & aggregations â†’ Gold
â”‚
â”œâ”€â”€ api_ingestion/
â”‚   â””â”€â”€ person_info_pipeline        # API pipeline from ReqRes â†’ Delta
â”‚
â””â”€â”€ README.md

ETL Pipeline
1ï¸âƒ£ Source â†’ Bronze

Input:

Country-Q1.csv, Department-Q1.csv, Employee-Q1.csv

Process:

Read CSV files with schema inference

Store raw datasets in catalog:
/source_to_bronze/employee.csv
/source_to_bronze/department.csv
/source_to_bronze/country.csv

2ï¸âƒ£ Bronze â†’ Silver

Steps:

Read bronze files with custom schema
Convert column names from CamelCase â†’ snake_case (UDF)
Add load_date column with current date
Write as Delta Table:

DB: Employee_info
Table: dim_employee
Path: /silver/Employee_info/dim_employee

3ï¸âƒ£ Silver â†’ Gold

Transformations:
Salary by department (descending order)
Employee counts per department per country
Department names with corresponding country names
Average employee age per department
Add at_load_date column for current_date

Question-2
ğŸŒ API Ingestion (ReqRes)

Source API: https://reqres.in/api/users

Process:

Fetch data dynamically (pagination until empty)

Drop unnecessary fields: page, per_page, total, total_pages, support

Apply custom schema & flatten JSON

Derive new column site_address from email domain (reqres.in)

Output:

Write to Delta:
DB: site_info
Table: person_info
Path: /site_info/person_info

ğŸ› ï¸ Tech Stack

Databricks (PySpark, Delta Lake)

DBFS for data storage

âœ… Commit History

ETL pipeline (CSV â†’ Bronze â†’ Silver â†’ Gold)

API pipeline (ReqRes â†’ Delta Lake)
Python for API handling & UDFs

SQL / DataFrames for transformations
Add load_date column
